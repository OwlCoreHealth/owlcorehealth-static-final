// ‚úÖ chat.js COMPLETO com integra√ß√£o do formul√°rio de subscri√ß√£o de e-mail (sem NENHUMA remo√ß√£o do seu c√≥digo)

import { getSymptomContext } from "./notion.mjs";
import { fallbackTextsBySymptom } from "./fallbackTextsBySymptom.js";

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const GPT_MODEL = "gpt-4o-mini";

let sessionMemory = {
  sintomasDetectados: [],
  respostasUsuario: [],
  nome: "",
  idioma: "pt",
  sintomaAtual: null,
  categoriaAtual: null,
  funnelPhase: 1,
  usedQuestions: [],
  emailOffered: false
};

function getFunnelKey(phase) {
  switch (phase) {
    case 1: return "base";
    case 2: return "gravidade";
    case 3: return "estatisticas";
    case 4: return "nutrientes";
    case 5: return "suplemento";
    case 6: return "cta";
    default: return "base";
  }
}
// Fun√ß√£o que gera resposta completa para o sintoma
const generateAnswerForSymptom = async (symptom, idioma) => {
  const prompt = idioma === "pt" ? promptPT : promptEN;
  
  // Chamar a API do GPT para gerar a resposta completa
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
    Authorization: `Bearer ${OPENAI_API_KEY}`
  },
  body: JSON.stringify({
    model: GPT_MODEL,
    messages: [
      { role: "system", content: "Voc√™ √© um assistente de sa√∫de fornecendo explica√ß√µes cient√≠ficas e pr√°ticas sobre sintomas." },
      { role: "user", content: prompt }
    ],
    temperature: 0.7,
    max_tokens: 500 // Aumente o n√∫mero de tokens aqui
  })
});

  const data = await response.json();
console.log("Resposta do servidor:", data); // Adicione este log para inspecionar a resposta completa

  
  // Retorna o conte√∫do gerado pela API
  return data.choices?.[0]?.message?.content || "Desculpe, n√£o consegui gerar uma resposta no momento.";
};

function getBotIconHTML() {
  return `<img src="owl-icon.png" alt="Owl Icon" class="bot-icon" style="width: 28px; margin-right: 12px;" />`;
}

// ‚úÖ ALTERA√á√ÉO NO formatHybridResponse para adicionar e-mail ap√≥s 1¬™ resposta com perguntas
function formatHybridResponse(context, gptResponse, followupQuestions, idioma) {
  const phaseTitle = idioma === "pt" ? "Vamos explorar mais:" : "Let's explore further:";
  const instruction = idioma === "pt"
    ? "Escolha uma das op√ß√µes abaixo para continuarmos:"
    : "Choose one of the options below to continue:";

  let response = gptResponse?.trim() || "";

  if (followupQuestions.length) {
    response += `\n\n${phaseTitle}\n${instruction}\n\n`;
    followupQuestions.slice(0, 3).forEach((q, i) => {
      response += `<div class="clickable-question" data-question="${encodeURIComponent(q)}" onclick="handleQuestionClick(this)">${i + 1}. ${q}</div>\n`;
    });

    // ‚úÖ Mostra o formul√°rio de e-mail na primeira vez que houver follow-ups
    if (!sessionMemory.emailOffered && sessionMemory.funnelPhase === 2) {
      sessionMemory.emailOffered = true;
     // response += renderEmailPrompt(idioma);
    }
  }

  return response;
}

async function classifyUserIntent(userInput, idioma) {
  const prompt = idioma === "pt"
    ? `Voc√™ √© um classificador de inten√ß√£o. Receber√° mensagens de usu√°rios e deve responder com uma das seguintes inten√ß√µes:

- sintoma
- sauda√ß√£o
- curiosidade
- pergunta funcional
- d√∫vida vaga
- outro

Mensagem do usu√°rio: "${userInput}"
Resposta (apenas a inten√ß√£o):`
    : `You are an intent classifier. You‚Äôll receive a user message and must reply with one of the following labels:

- symptom
- greeting
- curiosity
- functional_question
- vague_doubt
- other

User message: "${userInput}"
Answer (intent only):`;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
    Authorization: `Bearer ${OPENAI_API_KEY}`
  },
  body: JSON.stringify({
    model: GPT_MODEL,
    messages: [
      { role: "system", content: "Voc√™ √© um assistente de sa√∫de fornecendo explica√ß√µes cient√≠ficas e pr√°ticas sobre sintomas." },
      { role: "user", content: prompt }
    ],
    temperature: 0.7,
    max_tokens: 300
  })
});

    const data = await response.json();
    const intent = data.choices?.[0]?.message?.content?.trim().toLowerCase() || "outro";
    return intent;
  } catch (e) {
    console.error("Erro ao classificar inten√ß√£o:", e);
    return "outro";
  }
}

async function rewriteWithGPT(baseText, sintoma, idioma, funnelPhase, categoria) {
  const prompt = idioma === "pt"
    ? `Use o seguinte texto como base, mantendo o conte√∫do e estrutura, mas reescrevendo com 30% de liberdade criativa, usando linguagem mais fluida, provocadora e humana. Mantenha o foco exclusivamente no sintoma: ${sintoma} e na categoria: ${categoria}. N√£o aborde outros temas. N√£o mude o tema e mantenha o foco em: ${sintoma}\n\nTexto-base:\n${baseText}`
    : `Use the following text as a base. Keep the core message and structure, but rewrite with 30% creative freedom in a more natural, engaging, and human tone. Keep the focus exclusively on the symptom: ${sintoma} and category: ${categoria}. Do not address other topics. Do not change the topic and keep the focus on: ${sintoma}\n\nBase text:\n${baseText}`;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: GPT_MODEL,
        messages: [{ role: "system", content: prompt }],
        temperature: 0.65,
        max_tokens: 600
      })
    });

    const data = await response.json();
    return data.choices?.[0]?.message?.content?.trim() || baseText;
  } catch (e) {
    console.error("Erro ao reescrever com GPT:", e);
    return baseText;
  }
}

async function generateFreeTextWithGPT(prompt) {
  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: GPT_MODEL,
        messages: [{ role: "system", content: prompt }],
        temperature: 0.7,
        max_tokens: 700
      })
    });

    const data = await response.json();
    return data.choices?.[0]?.message?.content?.trim() || "";
  } catch (e) {
    console.error("Erro ao gerar texto livre com GPT:", e);
    return "";
  }
}

async function generateStrategicFollowUpQuestions(context, idioma) {
  const symptom = context.sintoma || "symptom";
  const phase = context.funnelPhase || 1;

  const promptPT = `
Voc√™ √© um assistente de sa√∫de inteligente, focado no sintoma "${symptom}". Gere 3 perguntas curtas, provocativas e impactantes que despertem curiosidade, medo ou desejo por solu√ß√£o, sem pedir que o usu√°rio escreva ou explique nada. As perguntas devem ser frases diretas, f√°ceis de ler, com foco na dor, medo ou benef√≠cio. N√£o pe√ßa explica√ß√µes, s√≥ perguntas que incentivem o clique.
Retorne apenas as 3 perguntas numeradas.
`;

  const promptEN = `
You are a smart health assistant focused on the symptom "${symptom}". Generate 3 short, provocative, and impactful questions that spark curiosity, fear, or desire for a solution, without asking the user to type or explain anything. The questions should be direct, easy to read, focusing on pain points, fears, or benefits. Do not ask for explanations, only questions that encourage clicking.
Return only the 3 numbered questions.
`;

  const prompt = idioma === "pt" ? promptPT : promptEN;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: GPT_MODEL,
        messages: [
          { role: "system", content: "You generate only 3 short, provocative and strategic questions. No explanations." },
          { role: "user", content: prompt }
        ],
        temperature: 0.8,
        max_tokens: 200
      })
    });

    const data = await response.json();
    let questionsRaw = data.choices?.[0]?.message?.content || "";
    let questions = questionsRaw.split(/\d+\.\s+/).filter(Boolean).slice(0, 3);

    // Remover perguntas j√° usadas para evitar repeti√ß√£o
    const usedQuestions = sessionMemory.usedQuestions || [];
    questions = questions.filter(q => !usedQuestions.includes(q));

    // Atualizar perguntas usadas na sess√£o
    sessionMemory.usedQuestions.push(...questions);

    // Caso gere menos que 3, pode-se adicionar fallback gen√©rico (opcional)
    if (questions.length < 3) {
      const fallback = idioma === "pt"
        ? [
            "Quer saber o que pode estar piorando esse sintoma?",
            "Sabia que pequenas mudan√ßas podem melhorar muito?",
            "Voc√™ conhece as solu√ß√µes naturais para isso?"
          ]
        : [
            "Want to know what might be worsening this symptom?",
            "Did you know small changes can improve it a lot?",
            "Do you know natural solutions for this?"
          ];
      for (const fq of fallback) {
        if (questions.length >= 3) break;
        if (!usedQuestions.includes(fq)) {
          questions.push(fq);
          sessionMemory.usedQuestions.push(fq);
        }
      }
    }

    return questions.slice(0, 3);

  } catch (e) {
    console.error("Erro ao gerar perguntas estrat√©gicas:", e);
    // Fallback simples caso d√™ erro
    return idioma === "pt"
      ? [
          "Quer saber mais sobre esse sintoma?",
          "Est√° pronto para descobrir solu√ß√µes eficazes?",
          "Gostaria de evitar que isso piore?"
        ]
      : [
          "Want to learn more about this symptom?",
          "Ready to discover effective solutions?",
          "Would you like to prevent it from worsening?"
        ];
  }
}

async function identifySymptom(userInput, symptomsList, idioma) {
  const promptPT = `
Voc√™ √© um assistente que identifica o sintoma mais pr√≥ximo de uma lista dada, a partir do texto do usu√°rio. 
A lista de sintomas √©:
${symptomsList.join(", ")}

Dado o texto do usu√°rio:
"${userInput}"

Responda apenas com o sintoma da lista que melhor corresponde ao texto do usu√°rio ou com o sintoma mais **semelhante** ou **relacionado**. Se n√£o reconhecer, responda "unknown".
  `;

  const promptEN = `
You are an assistant that identifies the closest symptom from a given list, based on the user's text.
The list of symptoms is:
${symptomsList.join(", ")}

Given the user's input:
"${userInput}"

Answer only with the symptom from the list that best matches or is most **similar** or **related** to the user's text. If no match, respond "unknown".
  `;

  const prompt = idioma === "pt" ? promptPT : promptEN;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: GPT_MODEL,
        messages: [
          { role: "system", content: "You are a precise symptom matcher." },
          { role: "user", content: prompt }
        ],
        temperature: 0,
        max_tokens: 20
      })
    });

    const data = await response.json();
    const match = data.choices?.[0]?.message?.content.trim() || "unknown";
    return match.toLowerCase();
  } catch (e) {
    console.error("Erro ao identificar sintoma:", e);
    return "unknown";
  }
}

export default async function handler(req, res) {
  if (req.method !== "POST") return res.status(405).json({ error: "M√©todo n√£o permitido" });

 const { message, selectedQuestion, idioma } = req.body;
const userInput = selectedQuestion || message;
const isFollowUp = Boolean(selectedQuestion);
const intent = await classifyUserIntent(userInput, idioma || "en");
let gptResponse;

// Declaro followupQuestions com valor padr√£o vazio para evitar ReferenceError
let followupQuestions = [];

if (isFollowUp) {
  const prompt = idioma === "pt"
    ? `Voc√™ √© o Dr. Owl, um assistente de sa√∫de inteligente. O sintoma atual √©: "${sessionMemory.sintomaAtual}". A fase do funil √©: ${sessionMemory.funnelPhase}. O usu√°rio clicou na pergunta: "${selectedQuestion}". Responda de forma clara, cient√≠fica e focada em avan√ßar a conversa sobre esse sintoma nesta fase. N√£o fa√ßa perguntas nem respostas vagas.`
    : `You are Dr. Owl, a smart health assistant. The current symptom is: "${sessionMemory.sintomaAtual}". The funnel phase is: ${sessionMemory.funnelPhase}. The user clicked the follow-up question: "${selectedQuestion}". Provide a clear, scientific, and focused response advancing the conversation about this symptom in this phase. Do not ask questions or give vague answers.`;

  gptResponse = await generateFreeTextWithGPT(prompt);

  // Em caso de follow-up, normalmente n√£o geramos novas perguntas,
  // mas se quiser gerar, fa√ßa aqui, ou deixe vazio (recomendado)
  followupQuestions = [];

} else if (intent !== "sintoma") {
  gptResponse = await generateFreeTextWithGPT(
    idioma === "pt"
      ? `Voc√™ √© o Dr. Owl, um assistente de sa√∫de inteligente e focado em fornecer explica√ß√µes cient√≠ficas e objetivas. Um usu√°rio fez uma pergunta fora do padr√£o de sintomas, que envolve curiosidade ou d√∫vida. Responda de forma clara, baseada em evid√™ncias cient√≠ficas, sem humor ou met√°foras. Pergunta do usu√°rio: "${userInput}"`
      : `You are Dr. Owl, a health assistant focused on providing scientific and objective explanations. A user has asked a question outside the symptom context, involving curiosity or doubt. Respond clearly, based on scientific evidence, without humor or metaphors. User's message: "${userInput}"`
  );

  followupQuestions = await generateStrategicFollowUpQuestions(
    { sintoma: sessionMemory.sintomaAtual, funnelPhase: sessionMemory.funnelPhase },
    idioma
  );

} else {
  // fluxo para intent === "sintoma"
  // ... seu c√≥digo atual para sintomas

  followupQuestions = await generateFollowUpQuestions(
    { sintoma: sessionMemory.sintomaAtual, funnelPhase: sessionMemory.funnelPhase },
    idioma
  );
}

// Continua normalmente
let content = formatHybridResponse({}, gptResponse, followupQuestions, idioma);

if (!sessionMemory.emailOffered && sessionMemory.funnelPhase === 2) {
  sessionMemory.emailOffered = true;
}

sessionMemory.funnelPhase = Math.min((sessionMemory.funnelPhase || 1) + 1, 6);
sessionMemory.genericEntry = true;
sessionMemory.genericMessages = sessionMemory.genericMessages || [];
sessionMemory.genericMessages.push(userInput);

return res.status(200).json({
  choices: [{ message: { content, followupQuestions } }]
});

  } else {
    // A PARTIR DAQUI: fluxo de tratamento do caso com sintoma
    const isPortuguese = /[\u00e3\u00f5\u00e7√°√©√≠√≥√∫]| voc√™|dor|tenho|problema|sa√∫de/i.test(userInput);
    const idiomaDetectado = isPortuguese ? "pt" : "en";
    sessionMemory.idioma = idiomaDetectado;
    const idioma = sessionMemory.idioma;

    const allSymptoms = Object.keys(fallbackTextsBySymptom);

    // Identifica o sintoma mais pr√≥ximo do input usando GPT
    const identifiedSymptom = await identifySymptom(userInput, allSymptoms, idioma);

    sessionMemory.sintomaAtual = identifiedSymptom === "unknown" ? userInput.toLowerCase() : identifiedSymptom;
    sessionMemory.nome = "";
    sessionMemory.respostasUsuario.push(userInput);

    let context = await getSymptomContext(
      sessionMemory.sintomaAtual,
      sessionMemory.nome,
      null, // idade removida
      null, // peso removido
      sessionMemory.funnelPhase,
      sessionMemory.sintomaAtual,
      sessionMemory.usedQuestions
    );

    if (context.sintoma && !sessionMemory.sintomaAtual) sessionMemory.sintomaAtual = context.sintoma;
    if (context.categoria && !sessionMemory.categoriaAtual) sessionMemory.categoriaAtual = context.categoria;

    // Gerar a explica√ß√£o completa do sintoma
    const answer = await generateAnswerForSymptom(sessionMemory.sintomaAtual, idioma);

    // Textos oficiais do Notion
    const funnelKey = getFunnelKey(sessionMemory.funnelPhase);
    let funnelTexts = context.funnelTexts?.[funnelKey] || [];

    // Tenta fallback pelo sintoma
    if (!funnelTexts.length) {
      const fallbackTexts = fallbackTextsBySymptom[sessionMemory.sintomaAtual?.toLowerCase().trim()] || {};
      funnelTexts = fallbackTexts[funnelKey] || [];
    }

    // (Opcional) fallback gen√©rico
    if (!funnelTexts.length) {
      funnelTexts = [
        idioma === "pt"
          ? "Desculpe, ainda n√£o temos conte√∫do para esse sintoma e etapa. Tente outro sintoma ou reformule sua pergunta."
          : "Sorry, we don‚Äôt have content for this symptom and phase yet. Please try another symptom or rephrase your query."
      ];
    }

    const baseText = funnelTexts[Math.floor(Math.random() * funnelTexts.length)];

    const gptResponse = baseText
      ? await rewriteWithGPT(baseText, sessionMemory.sintomaAtual, idioma, sessionMemory.funnelPhase, sessionMemory.categoriaAtual)
      : await rewriteWithGPT(
          `Explain clearly about the symptom ${sessionMemory.sintomaAtual} in phase ${sessionMemory.funnelPhase}, focusing on phase key ${funnelKey}`,
          sessionMemory.sintomaAtual,
          idioma,
          sessionMemory.funnelPhase,
          sessionMemory.categoriaAtual
        );

    const followupQuestions = await generateFollowUpQuestions(
      { sintoma: sessionMemory.sintomaAtual, funnelPhase: sessionMemory.funnelPhase },
      idioma
    );

    // Atualiza a fase do funil com seguran√ßa
    sessionMemory.funnelPhase = Math.min((context.funnelPhase || sessionMemory.funnelPhase || 1) + 1, 6);

    // Debug logs
    console.log("üß™ Sintoma detectado:", context.sintoma);
    console.log("üß™ Categoria atual:", sessionMemory.categoriaAtual);
    console.log("üß™ Fase atual:", sessionMemory.funnelPhase);
    console.log("üß™ Texto da fase:", funnelKey, funnelTexts);

    content = formatHybridResponse(context, gptResponse, followupQuestions, idioma);

    return res.status(200).json({
      choices: [{ message: { content, followupQuestions: followupQuestions || [] } }]
    });

  }
}
