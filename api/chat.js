// ‚úÖ chat.js COMPLETO com integra√ß√£o do formul√°rio de subscri√ß√£o de e-mail (sem NENHUMA remo√ß√£o do seu c√≥digo)

import { getSymptomContext } from "./notion.mjs";
import { fallbackTextsBySymptom } from "./fallbackTextsBySymptom.js";

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const GPT_MODEL = "gpt-4o-mini";

let sessionMemory = {
  sintomasDetectados: [],
  respostasUsuario: [],
  nome: "",
  idioma: "pt",
  sintomaAtual: null,
  categoriaAtual: null,
  funnelPhase: 1,
  usedQuestions: [],
  emailOffered: false
};
function getRandomFunnelText(context, funnelPhase) {
  const funnelColumnsMap = {
    1: ["Funnel 1 Variation 1", "Funnel 1 Variation 2", "Funnel 1 Variation 3"],
    2: ["Funnel 2 Variation 1", "Funnel 2 Variation 2", "Funnel 2 Variation 3"],
    3: ["Funnel 3 Variation 1", "Funnel 3 Variation 2", "Funnel 3 Variation 3"],
    4: ["Funnel 4 Variation 1", "Funnel 4 Variation 2", "Funnel 4 Variation 3"],
    5: ["Funnel 5 Variation 1", "Funnel 5 Variation 2", "Funnel 5 Variation 3"],
  };

  const columns = funnelColumnsMap[funnelPhase] || [];

  const texts = columns
    .map(col => context[col])
    .filter(text => typeof text === "string" && text.trim().length > 0);

  if (texts.length === 0) return null;

  return texts[Math.floor(Math.random() * texts.length)];
}

function getFunnelKey(phase) {
  switch (phase) {
    case 1: return "base";
    case 2: return "gravidade";
    case 3: return "estatisticas";
    case 4: return "nutrientes";
    case 5: return "suplemento";
    case 6: return "cta";
    default: return "base";
  }
}
// Fun√ß√£o que gera resposta completa para o sintoma
const generateAnswerForSymptom = async (symptom, idioma) => {
  const prompt = idioma === "pt" ? promptPT : promptEN;
  
  // Chamar a API do GPT para gerar a resposta completa
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
    Authorization: `Bearer ${OPENAI_API_KEY}`
  },
  body: JSON.stringify({
    model: GPT_MODEL,
    messages: [
      { role: "system", content: "Voc√™ √© um assistente de sa√∫de fornecendo explica√ß√µes cient√≠ficas e pr√°ticas sobre sintomas." },
      { role: "user", content: prompt }
    ],
    temperature: 0.7,
    max_tokens: 500 // Aumente o n√∫mero de tokens aqui
  })
});

  const data = await response.json();
console.log("Resposta do servidor:", data); // Adicione este log para inspecionar a resposta completa

  
  // Retorna o conte√∫do gerado pela API
  return data.choices?.[0]?.message?.content || "Desculpe, n√£o consegui gerar uma resposta no momento.";
};

function getBotIconHTML() {
  return `<img src="owl-icon.png" alt="Owl Icon" class="bot-icon" style="width: 28px; margin-right: 12px;" />`;
}

// ‚úÖ ALTERA√á√ÉO NO formatHybridResponse para adicionar e-mail ap√≥s 1¬™ resposta com perguntas
function formatHybridResponse(context, gptResponse, followupQuestions, idioma) {
  const phaseTitle = idioma === "pt" ? "Vamos explorar mais:" : "Let's explore further:";
  const instruction = idioma === "pt"
    ? "Escolha uma das op√ß√µes abaixo para continuarmos:"
    : "Choose one of the options below to continue:";

  let response = gptResponse?.trim() || "";

  if (followupQuestions.length) {
    response += `\n\n${phaseTitle}\n${instruction}\n\n`;
    followupQuestions.slice(0, 3).forEach((q, i) => {
      response += `<div class="clickable-question" data-question="${encodeURIComponent(q)}" onclick="handleQuestionClick(this)">${i + 1}. ${q}</div>\n`;
    });

    // ‚úÖ Mostra o formul√°rio de e-mail na primeira vez que houver follow-ups
    if (!sessionMemory.emailOffered && sessionMemory.funnelPhase === 2) {
      sessionMemory.emailOffered = true;
     // response += renderEmailPrompt(idioma);
    }
  }

  return response;
}

async function classifyUserIntent(userInput, idioma) {
  const prompt = idioma === "pt"
    ? `Voc√™ √© um classificador de inten√ß√£o. Receber√° mensagens de usu√°rios e deve responder com uma das seguintes inten√ß√µes:

- sintoma
- sauda√ß√£o
- curiosidade
- pergunta funcional
- d√∫vida vaga
- outro

Mensagem do usu√°rio: "${userInput}"
Resposta (apenas a inten√ß√£o):`
    : `You are an intent classifier. You‚Äôll receive a user message and must reply with one of the following labels:

- symptom
- greeting
- curiosity
- functional_question
- vague_doubt
- other

User message: "${userInput}"
Answer (intent only):`;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
    Authorization: `Bearer ${OPENAI_API_KEY}`
  },
  body: JSON.stringify({
    model: GPT_MODEL,
    messages: [
      { role: "system", content: "Voc√™ √© um assistente de sa√∫de fornecendo explica√ß√µes cient√≠ficas e pr√°ticas sobre sintomas." },
      { role: "user", content: prompt }
    ],
    temperature: 0.7,
    max_tokens: 300
  })
});

    const data = await response.json();
    const intent = data.choices?.[0]?.message?.content?.trim().toLowerCase() || "outro";
    return intent;
  } catch (e) {
    console.error("Erro ao classificar inten√ß√£o:", e);
    return "outro";
  }
}

async function rewriteWithGPT(baseText, sintoma, idioma, funnelPhase, categoria) {
  const prompt = idioma === "pt"
    ? `Use o seguinte texto como base, mantendo o conte√∫do e estrutura, mas reescrevendo com 30% de liberdade criativa, usando linguagem mais fluida, provocadora e humana. Mantenha o foco exclusivamente no sintoma: ${sintoma} e na categoria: ${categoria}. N√£o aborde outros temas. N√£o mude o tema e mantenha o foco em: ${sintoma}\n\nTexto-base:\n${baseText}`
    : `Use the following text as a base. Keep the core message and structure, but rewrite with 30% creative freedom in a more natural, engaging, and human tone. Keep the focus exclusively on the symptom: ${sintoma} and category: ${categoria}. Do not address other topics. Do not change the topic and keep the focus on: ${sintoma}\n\nBase text:\n${baseText}`;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: GPT_MODEL,
        messages: [{ role: "system", content: prompt }],
        temperature: 0.65,
        max_tokens: 600
      })
    });

    const data = await response.json();
    return data.choices?.[0]?.message?.content?.trim() || baseText;
  } catch (e) {
    console.error("Erro ao reescrever com GPT:", e);
    return baseText;
  }
}

async function generateFreeTextWithGPT(prompt) {
  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: GPT_MODEL,
        messages: [{ role: "system", content: prompt }],
        temperature: 0.7,
        max_tokens: 700
      })
    });

    const data = await response.json();
    return data.choices?.[0]?.message?.content?.trim() || "";
  } catch (e) {
    console.error("Erro ao gerar texto livre com GPT:", e);
    return "";
  }
}

async function generateStrategicFollowUpQuestions(sintoma, idioma) {
  const prompt = `
Voc√™ √© um assistente de sa√∫de inteligente focado em criar perguntas curtas, diretas e provocativas para engajar o usu√°rio sem pedir que ele escreva respostas.

Baseado no sintoma: "${sintoma}"

Gere 3 perguntas que:

- Despertem curiosidade, medo ou senso de urg√™ncia relacionado ao sintoma
- Apontem para dores, consequ√™ncias, solu√ß√µes ou medos reais
- Sejam claras e simples, sem exigir explica√ß√£o escrita
- Funcionem como ganchos para o usu√°rio clicar e seguir a conversa
- Nunca pe√ßam para o usu√°rio digitar ou explicar algo

Retorne apenas as 3 perguntas numeradas, em linguagem natural e no idioma "${idioma}".
`;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: GPT_MODEL,
        messages: [{ role: "user", content: prompt }],
        temperature: 0.75,
        max_tokens: 200
      })
    });

    const data = await response.json();
    const rawText = data.choices?.[0]?.message?.content || "";

    // Extrai perguntas numeradas (ex: "1. Pergunta")
    const questions = rawText
      .split(/\d+\.\s+/)
      .filter(q => q.trim().length > 0)
      .slice(0, 3)
      .map(q => q.trim());

    return questions;

  } catch (error) {
    console.error("Erro ao gerar perguntas estrat√©gicas:", error);
    // Fallback perguntas gen√©ricas estrat√©gicas
    return idioma === "pt"
      ? [
          "Quer descobrir o que pode estar piorando seu sintoma?",
          "Sabia que ignorar isso pode causar complica√ß√µes s√©rias?",
          "Quer saber uma forma r√°pida de aliviar esse problema?"
        ]
      : [
          "Want to discover what might be worsening your symptom?",
          "Did you know ignoring this can lead to serious complications?",
          "Want to learn a quick way to relieve this issue?"
        ];
  }
}

async function identifySymptom(userInput, symptomsList, idioma) {
  const promptPT = `
Voc√™ √© um assistente que identifica o sintoma mais pr√≥ximo de uma lista dada, a partir do texto do usu√°rio. 
A lista de sintomas √©:
${symptomsList.join(", ")}

Dado o texto do usu√°rio:
"${userInput}"

Responda apenas com o sintoma da lista que melhor corresponde ao texto do usu√°rio ou com o sintoma mais **semelhante** ou **relacionado**. Se n√£o reconhecer, responda "unknown".
  `;

  const promptEN = `
You are an assistant that identifies the closest symptom from a given list, based on the user's text.
The list of symptoms is:
${symptomsList.join(", ")}

Given the user's input:
"${userInput}"

Answer only with the symptom from the list that best matches or is most **similar** or **related** to the user's text. If no match, respond "unknown".
  `;

  const prompt = idioma === "pt" ? promptPT : promptEN;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: GPT_MODEL,
        messages: [
          { role: "system", content: "You are a precise symptom matcher." },
          { role: "user", content: prompt }
        ],
        temperature: 0,
        max_tokens: 20
      })
    });

    const data = await response.json();
    const match = data.choices?.[0]?.message?.content.trim() || "unknown";
    return match.toLowerCase();
  } catch (e) {
    console.error("Erro ao identificar sintoma:", e);
    return "unknown";
  }
}

export default async function handler(req, res) {
  if (req.method !== "POST") return res.status(405).json({ error: "M√©todo n√£o permitido" });

  const { message, selectedQuestion, idioma } = req.body;
  const userInput = selectedQuestion || message;
  const isFollowUp = Boolean(selectedQuestion);
  const intent = await classifyUserIntent(userInput, idioma || "en");
  let gptResponse;

  if (intent !== "sintoma") {
    gptResponse = await generateFreeTextWithGPT(
      idioma === "pt"
         ? `Voc√™ √© o Dr. Owl, um assistente de sa√∫de inteligente e focado em fornecer explica√ß√µes cient√≠ficas e objetivas. Um usu√°rio fez uma pergunta fora do padr√£o de sintomas, que envolve curiosidade ou d√∫vida. Responda de forma clara, baseada em evid√™ncias cient√≠ficas, sem humor ou met√°foras. Pergunta do usu√°rio: "${userInput}"`
        : `You are Dr. Owl, a health assistant focused on providing scientific and objective explanations. A user has asked a question outside the symptom context, involving curiosity or doubt. Respond clearly, based on scientific evidence, without humor or metaphors. User's message: "${userInput}"`
    );

   const followupQuestions = await generateStrategicFollowUpQuestions(sessionMemory.sintomaAtual, idioma);

    let content = formatHybridResponse({}, gptResponse, followupQuestions, idioma);

    if (!sessionMemory.emailOffered && sessionMemory.funnelPhase === 2) {
      sessionMemory.emailOffered = true;
    }

    sessionMemory.funnelPhase = Math.min((sessionMemory.funnelPhase || 1) + 1, 6);
    sessionMemory.genericEntry = true;
    sessionMemory.genericMessages = sessionMemory.genericMessages || [];
    sessionMemory.genericMessages.push(userInput);

    return res.status(200).json({
      choices: [{ message: { content, followupQuestions } }]
    });

  } else {
    // A PARTIR DAQUI: fluxo de tratamento do caso com sintoma
    const isPortuguese = /[\u00e3\u00f5\u00e7√°√©√≠√≥√∫]| voc√™|dor|tenho|problema|sa√∫de/i.test(userInput);
    const idiomaDetectado = isPortuguese ? "pt" : "en";
    sessionMemory.idioma = idiomaDetectado;
    const idioma = sessionMemory.idioma;

    const allSymptoms = Object.keys(fallbackTextsBySymptom);

    // Identifica o sintoma mais pr√≥ximo do input usando GPT
    const identifiedSymptom = await identifySymptom(userInput, allSymptoms, idioma);

    sessionMemory.sintomaAtual = identifiedSymptom === "unknown" ? userInput.toLowerCase() : identifiedSymptom;
    sessionMemory.nome = "";
    sessionMemory.respostasUsuario.push(userInput);

    let context = await getSymptomContext(
      sessionMemory.sintomaAtual,
      sessionMemory.nome,
      null, // idade removida
      null, // peso removido
      sessionMemory.funnelPhase,
      sessionMemory.sintomaAtual,
      sessionMemory.usedQuestions
    );

    if (context.sintoma && !sessionMemory.sintomaAtual) sessionMemory.sintomaAtual = context.sintoma;
    if (context.categoria && !sessionMemory.categoriaAtual) sessionMemory.categoriaAtual = context.categoria;

    // Gerar a explica√ß√£o completa do sintoma
    const answer = await generateAnswerForSymptom(sessionMemory.sintomaAtual, idioma);

    const baseText = getRandomFunnelText(context, sessionMemory.funnelPhase);

// Fallback pelo sintoma
if (!baseText) {
  const fallbackTexts = fallbackTextsBySymptom[sessionMemory.sintomaAtual?.toLowerCase().trim()] || {};
  const funnelKey = getFunnelKey(sessionMemory.funnelPhase);
  const fallbackTextArray = fallbackTexts[funnelKey] || [];
  if (fallbackTextArray.length) {
    baseText = fallbackTextArray[Math.floor(Math.random() * fallbackTextArray.length)];
  }
}

// Fallback gen√©rico
if (!baseText) {
  baseText = idioma === "pt"
    ? "Desculpe, ainda n√£o temos conte√∫do para esse sintoma e etapa. Tente outro sintoma ou reformule sua pergunta."
    : "Sorry, we don‚Äôt have content for this symptom and phase yet. Please try another symptom or rephrase your query.";
}

    const gptResponse = baseText
      ? await rewriteWithGPT(baseText, sessionMemory.sintomaAtual, idioma, sessionMemory.funnelPhase, sessionMemory.categoriaAtual)
      : await rewriteWithGPT(
          `Explain clearly about the symptom ${sessionMemory.sintomaAtual} in phase ${sessionMemory.funnelPhase}, focusing on phase key ${funnelKey}`,
          sessionMemory.sintomaAtual,
          idioma,
          sessionMemory.funnelPhase,
          sessionMemory.categoriaAtual
        );

    const followupQuestions = await generateFollowUpQuestions(
      { sintoma: sessionMemory.sintomaAtual, funnelPhase: sessionMemory.funnelPhase },
      idioma
    );

    // Atualiza a fase do funil com seguran√ßa
    sessionMemory.funnelPhase = Math.min((context.funnelPhase || sessionMemory.funnelPhase || 1) + 1, 6);

    // Debug logs
    console.log("üß™ Sintoma detectado:", context.sintoma);
    console.log("üß™ Categoria atual:", sessionMemory.categoriaAtual);
    console.log("üß™ Fase atual:", sessionMemory.funnelPhase);
    console.log("üß™ Texto da fase:", funnelKey, funnelTexts);

    content = formatHybridResponse(context, gptResponse, followupQuestions, idioma);

    return res.status(200).json({
      choices: [{ message: { content, followupQuestions: followupQuestions || [] } }]
    });

  }
}
